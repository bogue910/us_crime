---
title: "US_Crime"
output:
  word_document: default
---

# 9.1
```{r}
rm(list = ls())
set.seed(21)
crime <- read.table('uscrime.txt', stringsAsFactors = FALSE, header = TRUE)
#install.packages('backports')
library(backports)
#install.packages("corrr")
library('corrr')
#install.packages("ggcorrplot")
library(ggcorrplot)
#install.packages("FactoMineR")
library("FactoMineR")
#install.packages("factoextra")
library(factoextra)
#install.packages('GGally')
library(GGally)

# Compute PCA
crime_pca <- prcomp(crime[,1:15], scale=TRUE)
summary(crime_pca)

# Matrix of Eigenvectors
crime_pca$rotation

# Get the first 'couple' principal components
pc_comp <- crime_pca$x[,1:4]
pc_unrotated <- crime_pca$x[,1:4] %*% t(crime_pca$rotation[,1:4])
cor(pc_unrotated)

# Linear regression model with first couple PC
crimePC <- cbind(pc_unrotated, crime[,16])
model_pca <- lm(V16~., data = as.data.frame(crimePC))
summary(model_pca)

model_pca$coefficients[2:5] %*% t(crime_pca$rotation[,1:4])

# Get the 'betas' from the PC regression model
betas <- model_pca$coefficients[2:5]

# Get the scaling factors from the PCA
scaling_factors <- crime_pca$sdev[1:4]

# Transform 'betas' into 'alphas' in terms of the original scaled variables
alphas <- betas / scaling_factors

# Unscale the coefficients to represent them in terms of the original unscaled variables
unscaled_alphas <- alphas * sd(crime[, 16])

# Extract the variable names
variable_names <- names(crime)[1:4]

# Create a data frame to store the unscaled alphas with their corresponding variable names
coefficients_df <- data.frame(variable = variable_names, unscaled_alpha = unscaled_alphas)

# Print the coefficients in terms of the original unscaled variables
print(coefficients_df)
```
# 9.1 Analysis
It appears that the original regression model (Question 8.2) provides more comprehensive results compared to the PCA regression model (Question 9.1). The original model includes more variables and provides coefficients, p-values, and AIC (Akaike Information Criterion) values.

# 10.1
```{r}
rm(list = ls())
set.seed(21)
crime <- read.table('uscrime.txt', stringsAsFactors = FALSE, header = TRUE)
library(rpart.plot)
library(rpart)
library(tree)
library(randomForest)

# Fit a tree function to the crime data
crime_tree <- tree(Crime~., data = crime)
summary(crime_tree)

# Visualize the crime tree
plot(crime_tree)

yhat_tree <- predict(crime_tree)
plot(yhat_tree, crime$Crime)

prune.tree(crime_tree)$size
prune.tree(crime_tree)$dev
cv.tree(crime_tree)$dev

# 1. The tree model reveals the hierarchical structure of predictors that contribute to predicting crime rates. The top-level splits in the tree represent the most important variables for crime prediction.
# 2. Pruning the tree allows us to find a simpler model with a smaller number of splits while maintaining reasonable predictive performance. The optimal tree size and deviance can be examined to strike a balance between model complexity and performance.

# Create a randomForest tree
num_pred <- 4
crime_rf <- randomForest(Crime~., 
                         data = crime, 
                         mtry = num_pred,
                         importance = TRUE,
                         ntree = 500)
crime_rf
importance(crime_rf)

# Describe qualitative takeaways
# 1. The random forest model provides insights into variable importance, which helps identify the most influential predictors for crime rates.
# 2. The random forest model's out-of-bag error estimate (`crime_rf`) can be used to assess its overall predictive accuracy. Lower out-of-bag error suggests better model performance.
```
# 10.3
```{r}
rm(list = ls())
library(pROC)
german <- read.table('germancredit.txt', sep = " ")
head(german)

# Make response variable binary in terms of 0 and 1
german$V21[german$V21==1]<-0
german$V21[german$V21==2]<-1
head(german)

# Split the data into training and test
german_train <- german[1:800,]
german_test <- german[801:1000,]

# Create logistic regr model
german_model = glm(V21~.,
                   family = binomial(link = 'logit'),
                   data = german_train)
summary(german_model)

yhat <- predict(german_model, german_test, type = 'response')
roc(german_test$V21, round(yhat))

# Look at different threshold probability
thresh <- 0.8
yhat_thresh <- as.integer(yhat > thresh)
conf_matrix <- as.matrix(table(yhat_thresh, german_test$V21))
conf_matrix

# Specify the misclassification costs
cost_good_as_bad <- 1
cost_bad_as_good <- 5

# Create a sequence of threshold probabilities
thresholds <- seq(0, 1, by = 0.05)

# Initialize variables to store the misclassification costs
misclassification_costs <- rep(Inf, length(thresholds))


for (i in 1:length(thresholds)) {
  # Apply the threshold probability to classify as "good" or "bad" based on predicted probabilities
  yhat_thresh <- as.integer(yhat > thresholds[i])
  
  # Create a confusion matrix
  conf_matrix <- as.matrix(table(yhat_thresh, german_test$V21))
  
  # Check if the dimensions of conf_matrix are valid
  if (nrow(conf_matrix) >= 2 && ncol(conf_matrix) >= 2) {
    # Calculate misclassification costs
    misclassification_costs[i] <- (conf_matrix[2, 1] * cost_bad_as_good) +
                                 (conf_matrix[1, 2] * cost_good_as_bad)
  } else {
    # If dimensions are not valid, set misclassification costs to Inf
    misclassification_costs[i] <- Inf
  }
}

best_threshold <- thresholds[which.min(misclassification_costs)]

# Print the best threshold probability
print(paste("Best Threshold Probability:", best_threshold))
```

